{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc7617-b7f5-4585-8c15-72d731c80a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf08b1f7-2f6f-4f5d-87d7-3e014085cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be7f9dd-e3e0-437c-8713-9013edcd9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asmee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b689c-3959-4ef0-8d9d-a2e4ef6cd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01a8ddd-450f-41dd-ac6d-cfbd4a6575f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing is an exciting area.', 'We are studying about nltk.']\n",
      "['Natural', 'language', 'processing', 'is', 'an', 'exciting', 'area', '.', 'We', 'are', 'studying', 'about', 'nltk', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Natural language processing is an exciting area. We are studying about nltk.\"\n",
    "\n",
    "print(sent_tokenize(text))\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63373a-a2f0-4787-b388-c3f94a998faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 3 stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd428a6-718f-4075-a2c5-d3a32defa6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60cdadf-7927-46c3-8fb0-754df8c15e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = RegexpStemmer('ing$|ed$|able$|es$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890cd03e-5473-4049-9e1b-c42768aa6a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bathing ---> bath\n",
      "bathed ---> bath\n",
      "advisable ---> advis\n",
      "bases ---> bas\n"
     ]
    }
   ],
   "source": [
    "words = ['bathing','bathed','advisable','bases']\n",
    "for word in words:\n",
    "    print(word,\"--->\",regexp.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cd6f2c-531b-41b5-b421-067955f68dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asmee\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b554435-f4b0-4197-a66c-cd2b4a8b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural language processing is an exciting area. We are studying about nltk. I like to listen to Taylor Swift\"\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc42dfd-9006-40db-a7ed-7c6eababbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe61394-4038-4944-9851-e862f06db977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized tokens: ['Natural', 'language', 'processing', 'is', 'an', 'exciting', 'area', '.', 'We', 'are', 'studying', 'about', 'nltk', '.', 'I', 'like', 'to', 'listen', 'to', 'Taylor', 'Swift']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305c0f8-84d0-4eb6-9fb7-be5ad4787cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
